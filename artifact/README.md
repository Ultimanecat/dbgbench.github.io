
## How to use the ESEC/FSE 2017 artifact

The `DBGBENCH` artifact provides materials drawn from a large-scale debugging study with human participants. 
A comprehensive description of the shared dataset and infrastructure is provided in the 
[project website] (https://dbgbench.github.io). In general, the provided artifact can be used for several 
purposes that might well go beyond the scope of our ESEC/FSE 2017 paper. In the following, we will explicitly 
outline two usage scenarios to help understand the scope of our work. 


### Extending the `DBGBENCH` dataset

In order to carry out a similar study and extend the `DBGBENCH` dataset, we provide all questionnaire and 
the necessary computational infrastructure. Specifically, the following steps should be carried out in 
order to replicate the study environment:

1. [Install the docker virtual infrastructure] (https://dbgbench.github.io/docker/). This docker includes 
all the necessary source code as well as tests to manifest the investigated bugs. It can be shared with 
the study participant. 

2. [Download tutorial materials] (https://drive.google.com/open?id=0Bx6dkN27OssKVWJYZGdXcWdWQ0U) that 
include slides and videos to provide details about the study to participants. 

3. [Download example questionnaire] (https://dbgbench.github.io/questionnaire.pdf) for the study 
participants. For each bug under investigation, this questionnaire needs to filled up by a participant 
after she finishes debugging. The questionnaire can be set up in an online form (e.g. Google form) to 
make it easily accessible by the participants. 


### Using the `DBGBENCH` dataset

The `DBGBENCH` dataset collected data from 12 professional developers debugging 27 real-world bugs. 
This dataset is provided in a comprehensive format in the [project website] (https://dbgbench.github.io).

One of the primary usage of `DBGBENCH` dataset is to compare the effectiveness of automated debugging tools, 
in particular, **automated fault localization** and **automated repair** tools. In the following, we 
outline a few examples:

1. We provide scripts to check the plausibility of patches provided by participants. Please follow these 
[instructions] (https://dbgbench.github.io/patches/) to apply and check plausibility of participant-provided 
patches. 

2. We provide fault locations as provided by the participants. These fault locations are manually cross 
checked to validate their correctness. See the plaintext version of such a fault location [here] (https://dbgbench.github.io/find.24e2271e.faults.txt). 
These fault locations can be used for validating an automated fault localization tool. As an example, 
for statistical fault localization tools, participant-provided fault locations can be compared with 
the most suspicious statements reported by the fault localization tool. 

3. We provide participant-provided patches for each bug. For example, see all the patches and their 
categorizations (plausible and/or correct) provided for the bug `find.24e2271e` [here] (https://github.com/dbgbench/dbgbench.github.io/tree/master/patches/find.24e2271e).
These patches can be used to compare the readability, structure and correctness of patches generated by 
automated repair tools.

4. We provide diagnosis of each bug (in natural language) as provided by the study participants. See the 
plaintext version of such diagnosis [here] (https://dbgbench.github.io/find.24e2271e.diagnosis.txt). Such 
diagnoses can be leveraged upon to generate natural-language explanations of common bug types. Such 
explanations can further be used to design and evaluate sophisticated debugging tools that highlight suspicious locations 
along with a possible explanation of the bug. 

5. We also provide data on the average time and the average number of correct fixes for each bug in the 
[project website] (https://dbgbench.github.io). This data can be used to evaluate automated debugging 
tools in the future. In particular, we hypothesize that a necessary (but not sufficient) condition to 
validate automated fault localization and repair tools is to outperform the study participants. 


### Final note

The entire `DBGBENCH` dataset can be downloaded as a [single file] (https://docs.google.com/spreadsheets/d/12dYERCbuVCX6Ks4QgAF-XEEsLIxD9zsm2XAHE1bhyK0/edit?usp=sharing). 
Apart from the aforementioned use cases, researchers and professionals may take advantage of this dataset 
in ways that best match their research interests. 






